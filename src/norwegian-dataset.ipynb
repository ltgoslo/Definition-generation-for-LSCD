{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import gzip\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import string\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.expanduser(\"~/defmod/datasets/norwegian/ordbok-dump-2023-05-09.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95436\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(data_path, \"ordbok-nno-dump-2023-05-09.json\"), \"r\") as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80124\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(data_path, \"ordbok-nob-dump-2023-05-09.json\"), \"r\") as f:\n",
    "    data_bokmål = json.load(f)\n",
    "    \n",
    "print(len(data_bokmål))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad69edf9fc134b4fb9041ca59ada806c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80124 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lemma2idx = {}\n",
    "\n",
    "for i, word in enumerate(tqdm(data_bokmål)):\n",
    "    if word.get(\"lemmas\"):\n",
    "        lemma = word['lemmas'][0][\"lemma\"]\n",
    "        lemma2idx[lemma] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2626"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemma2idx[\"atferdsforsking\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35829"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemma2idx[\"næringsinnhold\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35826"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemma2idx[\"næringsdrivende\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bokmål[2626]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "есть объяснения к примерам {'quote': {'items': [], 'content': 'har en sagt a, får en (også) si b'}, 'type_': 'example', 'explanation': {'items': [], 'content': 'har en først begynt på noe, får en også fullføre det'}}\n",
    "\n",
    "если нижние индексы типа О2 пишем как обычные цифры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DICT_OF_CONTRACTIONS = {'contraction': [], 'type':[], 'lemma':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['contraction', 'type', 'lemma', 'full'], dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CONTRACTIONS_FILENAME = \"ordboka_contractions\"\n",
    "contractions = pd.read_csv(f'{CONTRACTIONS_FILENAME}.txt', sep=\"\\t\", encoding=\"utf-8\")\n",
    "contractions.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "contractions_dict = {row[1].contraction: row[1].full for row in contractions.iterrows()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_items(element_items, lemma, collect_contractions=False): #element_[\"items\"]\n",
    "    items = []\n",
    "    for item in element_items:\n",
    "        if item['type_'] in {'usage', 'subscript', 'superscript'}:\n",
    "            items.append(item[\"text\"])\n",
    "        elif item['type_'] == 'article_ref': \n",
    "            if item.get('word_form'):\n",
    "                items.append(item['word_form'])\n",
    "            else:\n",
    "                items.append(item['lemmas'][0]['lemma'])\n",
    "                #  word_form может не быть, если слово не изменяется\n",
    "        elif item['type_'] in TYPES_WITH_IDS:\n",
    "            items.append(contractions_dict.get(item['id'], item['id']))\n",
    "            if collect_contractions:\n",
    "                DICT_OF_CONTRACTIONS['contraction'].append(item['id'])\n",
    "                DICT_OF_CONTRACTIONS['type'].append(item['type_'])\n",
    "                DICT_OF_CONTRACTIONS['lemma'].append(lemma)\n",
    "\n",
    "        elif item['type_'] == 'quote_inset':\n",
    "            quote_content = item['content']\n",
    "            inset_items = collect_items(item[\"items\"], lemma)\n",
    "            try:\n",
    "                items.append(replace_dollars(inset_items, quote_content))\n",
    "            except IndexError:\n",
    "                print(f\"{item} caused index error in quote inset\")\n",
    "\n",
    "        elif item['type_'] == 'fraction':\n",
    "            items.append(f\"{item['numerator']}/{item['denominator']}\")\n",
    "\n",
    "        else:\n",
    "            print(item)\n",
    "    return items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dollar_pattern=re.compile(r\"\\$\")\n",
    "def replace_dollars(items, content):\n",
    "    offset = 0\n",
    "    for i, dollar in enumerate(re.finditer(dollar_pattern, content)):\n",
    "        start = dollar.start() + offset\n",
    "        end = dollar.end() + offset\n",
    "\n",
    "        content = content[:start] + items[i] + content[end:]\n",
    "        offset += len(items[i]) - 1\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_dollars_with_items(content, element_, lemma):\n",
    "    if '$' in content:\n",
    "        items = collect_items(element_[\"items\"], lemma)\n",
    "        #print(f\"Old content: {content}\")\n",
    "        if items: # для статьи про знак доллара будут пустые \n",
    "            content = replace_dollars(items, content)\n",
    "    #print(f\"New content: {content}\")\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "PUNCTUATION = re.compile(r\"[!\\?\\.]+$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPTS = (\n",
    "' Hva betyr ',\n",
    "' What is the definition of ',\n",
    "' Kva betyr ',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_example(df, prompt_id, add_prompt):\n",
    "    content = df.example\n",
    "    lemma = df.word\n",
    "    if isinstance(content, str):\n",
    "        if re.search(PUNCTUATION, content.strip()) is not None:\n",
    "            if add_prompt:\n",
    "                df.example = content + f'{PROMPTS[prompt_id]}{lemma}?'\n",
    "            return df\n",
    "        if add_prompt:\n",
    "            df.example = content + f'.{PROMPTS[prompt_id]}{lemma}?'\n",
    "        else:\n",
    "            df.example = content + '.'\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_subdefinition(\n",
    "    element_,\n",
    "    current_definition,\n",
    "    examples,\n",
    "    gold_definitions,\n",
    "    lemma,\n",
    "    prompt_id,\n",
    "    targets,\n",
    "    pos,\n",
    "    poses,\n",
    "):\n",
    "    sub_definitions = element_['elements']\n",
    "    sub_defined = current_definition\n",
    "    for sub_definition in sub_definitions:\n",
    "        if sub_definition['type_'] == 'explanation':\n",
    "            content = sub_definition[\"content\"]\n",
    "            content = replace_dollars_with_items(content, sub_definition, lemma)\n",
    "            sub_defined = current_definition + ' ' + content\n",
    "            \n",
    "        elif sub_definition['type_'] == 'example':\n",
    "            #print('example')\n",
    "            sub_definition = sub_definition['quote']\n",
    "            content = sub_definition[\"content\"]\n",
    "            content = replace_dollars_with_items(content, sub_definition, lemma)\n",
    "            \n",
    "            \n",
    "            try:\n",
    "                gold_definitions.append(sub_defined)\n",
    "            except UnboundLocalError:\n",
    "                print(element_)\n",
    "                raise UnboundLocalError\n",
    "            examples.append(content)\n",
    "            poses.append(pos)\n",
    "            targets.append(lemma)\n",
    "            \n",
    "        \n",
    "    return examples, gold_definitions, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "TYPES_WITH_IDS = {\n",
    "'relation',\n",
    "'domain',\n",
    "'entity',\n",
    "'temporal',\n",
    "'language',\n",
    "'grammar',\n",
    "'rhetoric',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint as print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(data, prompt_id, spraak=\"norwegian\", add_prompt=False):\n",
    "    examples, gold_definitions, targets, poses = [], [], [], []\n",
    "    \n",
    "    for i, word in enumerate(tqdm(data)):\n",
    "        if word.get(\"lemmas\"):\n",
    "            lemma = word['lemmas'][0][\"lemma\"]\n",
    "            \n",
    "            #print(f\"Lemma: {lemma}\")\n",
    "            pos = word['lemmas'][0]['paradigm_info'][0]['inflection_group'].split(\"_\")[0]\n",
    "            \n",
    "            definitions = word['body']['definitions']\n",
    "            definitions_examples = {}\n",
    "            for definition in definitions:\n",
    "                if definition.get('elements') is None:\n",
    "                    #print(f\"Lemma: {lemma}\") # такое слово только одно и на сайте его вообще нет\n",
    "                    #print(f\"No elements in {definition}\")\n",
    "                    continue\n",
    "                current_definition, content = '', ''\n",
    "                for element in definition[\"elements\"]:\n",
    "                    if element.get('elements') is not None:\n",
    "                        # много определений?\n",
    "                        current_definition = ''\n",
    "                        for element_ in element[\"elements\"]:\n",
    "                            if element_['type_'] in {\"definition\", \"explanation\"}:\n",
    "                                \n",
    "                                #print('Definition or explanation')\n",
    "                                if not element_.get('sub_definition'):\n",
    "                                    if not element_.get('elements'):\n",
    "\n",
    "                                        content = element_[\"content\"]\n",
    "                                        content = replace_dollars_with_items(content, element_, lemma)\n",
    "                                        if current_definition:\n",
    "                                            current_definition = current_definition + ', ' + content\n",
    "                                        else: \n",
    "                                            current_definition = content\n",
    "\n",
    "                                    else: #есть пара мест где sub_definition не подписано но оно есть\n",
    "                                        examples, gold_definitions, targets = handle_subdefinition(\n",
    "                                            element_,\n",
    "                                            current_definition,\n",
    "                                            examples,\n",
    "                                            gold_definitions,\n",
    "                                            lemma,\n",
    "                                            prompt_id,\n",
    "                                            targets,\n",
    "                                            pos,\n",
    "                                            poses,\n",
    "                                        )\n",
    "                                else:\n",
    "                                    examples, gold_definitions, targets = handle_subdefinition(\n",
    "                                        element_,\n",
    "                                        current_definition,\n",
    "                                        examples,\n",
    "                                        gold_definitions,\n",
    "                                        lemma,\n",
    "                                        prompt_id,\n",
    "                                        targets,\n",
    "                                        pos,\n",
    "                                        poses,\n",
    "                                    )\n",
    "\n",
    "                            elif element_['type_'] == 'example':\n",
    "                                #print('example')\n",
    "                                element_ = element_['quote']\n",
    "                                content = element_[\"content\"]\n",
    "                                content = replace_dollars_with_items(content, element_, lemma)\n",
    "\n",
    "                                gold_definitions.append(current_definition)\n",
    "                                examples.append(content)\n",
    "                                poses.append(pos)\n",
    "                                targets.append(lemma)\n",
    "\n",
    "                    else:\n",
    "                        #print('No elements in elements')\n",
    "                        #print(element['type_'])\n",
    "                        try:\n",
    "                            if element['type_'] in {\"definition\", \"explanation\"}:\n",
    "                                #print('Definition or explanation')\n",
    "                                content = replace_dollars_with_items(element['content'], element, lemma)\n",
    "\n",
    "                                if current_definition:\n",
    "                                    current_definition = current_definition + ', ' + content\n",
    "                                else: \n",
    "                                    current_definition = content\n",
    "\n",
    "                            elif element['type_'] == 'example':\n",
    "                                #print('example')\n",
    "                                element = element['quote']\n",
    "                                content = replace_dollars_with_items(element['content'], element, lemma)\n",
    "\n",
    "\n",
    "                                gold_definitions.append(current_definition)\n",
    "                                examples.append(content)\n",
    "                                targets.append(lemma)\n",
    "                                poses.append(pos)\n",
    "                        except IndexError:\n",
    "                            print(element)\n",
    "                            raise IndexError\n",
    "                gold_definitions.append(current_definition)\n",
    "                examples.append(content)\n",
    "                targets.append(lemma)\n",
    "                poses.append(pos)\n",
    "\n",
    "    df = pd.DataFrame({\"word\": targets, 'gloss': gold_definitions, 'example': examples, 'POS': poses,})\n",
    "    print(df.shape)\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    print(df.shape)\n",
    "    df.replace('', np.nan, inplace=True)\n",
    "    print(df[df.example.isna()])\n",
    "    df.dropna(subset=\"gloss\", inplace=True)\n",
    "    print(df.shape)\n",
    "    folder_path = os.path.expanduser(f'{spraak}/')\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.mkdir(folder_path)\n",
    "    filename = os.path.join(folder_path, 'complete.tsv.gz')\n",
    "    print(f\"\\nWriting to {filename}\")\n",
    "    df.to_csv(filename, sep=\"\\t\", index=False, encoding=\"utf-8\", compression='gzip')\n",
    "    print(df.columns)\n",
    "    filename = \"no_examples_allowed\"\n",
    "    df = df.apply(lambda x: make_example(x, prompt_id, add_prompt), axis=1)\n",
    "    if add_prompt:\n",
    "        df = df.drop(\"word\", axis=1)\n",
    "        filename = PROMPTS[prompt_id].translate(\n",
    "        str.maketrans(string.punctuation + \" \", '_'*(len(string.punctuation) + 1)),\n",
    "    )\n",
    "    \n",
    "    filename = f'{spraak}_finetuning_{filename}.tsv.gz'\n",
    "    print(df.columns)\n",
    "    print(f\"\\nWriting to {filename}\")\n",
    "    df.to_csv(filename, sep=\"\\t\", index=False, encoding=\"utf-8\", compression='gzip')  \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6285344e4ba14b82b0e6e58916739522",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80124 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150774, 4)\n",
      "(121659, 4)\n",
      "             word gloss example   POS\n",
      "98      absentere   NaN     NaN  VERB\n",
      "187       ad acta   NaN     NaN   ADV\n",
      "190          adam   NaN     NaN  NOUN\n",
      "347      ad undas   NaN     NaN   ADV\n",
      "679          akke   NaN     NaN  VERB\n",
      "...           ...   ...     ...   ...\n",
      "149547       kåte   NaN     NaN  VERB\n",
      "150335       grav   NaN     NaN   ADV\n",
      "150394  kuppelhue   NaN     NaN  NOUN\n",
      "150588      velde   NaN     NaN  NOUN\n",
      "150770    klesvei   NaN     NaN  NOUN\n",
      "\n",
      "[532 rows x 4 columns]\n",
      "(119476, 4)\n",
      "'\\nWriting to norwegian/complete.tsv.gz'\n",
      "Index(['word', 'gloss', 'example', 'POS'], dtype='object')\n",
      "Index(['word', 'gloss', 'example', 'POS'], dtype='object')\n",
      "'\\nWriting to norwegian_finetuning_no_examples_allowed.tsv.gz'\n"
     ]
    }
   ],
   "source": [
    "nb_0 = create_dataset(data_bokmål, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_dataset(data_bokmål, 1)\n",
    "create_dataset(data, 2, \"nynorsk\")\n",
    "create_dataset(data, 1, \"nynorsk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contractions_df = pd.DataFrame(DICT_OF_CONTRACTIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contractions_df.drop_duplicates(subset=['contraction'], inplace=True)\n",
    "contractions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#contractions_df.to_csv(f'{CONTRACTIONS_FILENAME}.tsv', sep=\"\\t\", index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "убрать определения типа brukt som substantiv? - don't drop them so far"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "glossannotator",
   "language": "python",
   "name": "glossannotator"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

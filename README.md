# Definition Generation for Lexical Semantic Change Detection (LSCD)

This repository contains the code and some data for the paper [Definition generation for lexical semantic change detection](https://arxiv.org/abs/2406.14167) by Mariia Fedorova, Andrey Kutuzov and Yves Scherrer.

## Repository structure
    ├── definition_generation   # generating definitions    .
    ├── definition_embeddings   # APD and PRT experiments (section 4.2. in the paper)
    ├── embed_definitions       # generating definitions' embeddings (section 4.2. in the paper)
    ├── src                     # other experiments (definitions-as-strings, etc) and evaluation, see more in the README file (sections 4.1, 4.3 in the paper)
    ├── generated_definitions   # prompts and definitions generated by us

## Obtaining the data

### Lists of words and ground truth

```src/data/``` 

### Diachronic corpora

Sampled usage examples with prompts and generated definitions can be found in ```generated_definitions/```.

The usage examples were sampled from the following resources:

- [English](https://www.ims.uni-stuttgart.de/en/research/resources/corpora/sem-eval-ulscd-eng/)
- Norwegian: [NBDigital corpus](https://www.nb.no/sprakbanken/ressurskatalog/oai-nb-no-sbr-34/) and [Norsk aviskorpus](https://www.nb.no/sprakbanken/ressurskatalog/oai-nb-no-sbr-4/) (available under [CC-BY-NC](https://creativecommons.org/licenses/by-nc/4.0/))
- [Russian](https://ruscorpora.ru/new/en/corpora-usage.html); the corpora's license does not allow publishing them; for that reason, we could only release the prompts and definitions without usage examples. Any other corpus may be used instead of it (although the results may be different then).

## Definition generation and evaluation

```commandline
cd definition_generation
git clone git@github.com:ltgoslo/definition_modeling.git
./definition_generation_pipeline.sh ${}
```
Read about the generation parameters in the [README file](definition_generation/README.md).

## [Reproducing the baselines](https://github.com/ltgoslo/Definition-generation-for-LSCD/tree/main/src#reproducing-lesk-baselines) (Table 2)

## Reproducing evaluation of LSCD performance with definition embeddings obtained with different decoding strategies (Table 3)

### WARNING

Scripts in `definition_embeddings/` are SLURM scripts, loading cluster-specific modules. For easier use in generic settings, we commented out `module use` and `module load` commands.
(In fact, APD and PRT themselves do not require a GPU to be run - but computing sentence transformers embeddings for all usage examples in reasonable time does).

In order to reproduce the whole experiment, create sentence transformers embeddings of usage examples using `embed_definitions/embed_definitions.py` (`embed_definitions/embeddings.slurm` shows an example of running it on a cluster, don't forget to replace account name and modules used) and run `compute_scores.sh` to compute the per-word change scores.
```commandline
cd embed_definitions
./embeddings.slurm
cd ../definition_embeddings
./compute_scores.sh
```

Then run evaluation:

```commandline
./evaluate.sh
```

## Reproducing evaluation of LSCD performance with merged definitions obtained with different decoding strategies (Table 4)

```commandline
./merge_all.sh
```

## Reproducing evaluation of both baseline and merged definitions LSCD in one run

This assumes that you already have all your predictions in `src/predictions/`

```commandline
cd src/analysis/
python eval_all.py
```

This will create src/analysis/result.txt with Spearman correlation scores and p-values for all methods. Insignificant correlations will be highlighted.

## Reproducing Figure 1

`src/analysis/graphs.ipynb`
